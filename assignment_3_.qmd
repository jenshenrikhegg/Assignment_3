
title: "assignment_3"


## introduksjon
## Dette arbeidskravet går ut på å simulere ein populasjon som representerer mulige forskjeller mellom to behandlinger fra ein crossover-studie, der deltakarane har gjennomgått begge behandlingstypene. formålet er å trekke tilfeldige utvalg av denne populasjonen samt beregne relevante statistiske mål og deretter tolke resultatet. 

## I tillegg til ein enkel analyse av enkelte utvalg, skal eg utføre fleire simuleringer for å forstå korleis utvalgsstørrelsen og variabiliteten påverker våre statistiske estimater. Dette vil gi meg ein innsikt i viktige statistiske begreper som estimater, standardfeil, t-verdi og p-verdi, og korleis desse påverkes av ulik utvalgsstørrelse og variabilitet i populasjonen.

#installering av nødvendige packages og aktivering av pakkene
```{r}
library(tidyverse)
library(ggplot2)
library(pwr)
library(dplyr)
install.packages("pwr")
install.packages("dplyr")

set.seed(1)
population <- rnorm(1000000, mean = 1.5, sd = 3)


samp1 <- data.frame(y = sample(population, 8, replace = FALSE))

samp2 <- data.frame(y = sample(population, 40, replace = FALSE))


m1 <- lm(y ~ 1, data = samp1)
m2 <- lm(y ~ 1, data = samp2)

summary(m1)
```

#1.
#Forklaring av estimering, standardfeil, t-verdi og p-verdi fra regresjonsmodellene m1 og m2:
Estimate: Estimatet i regresjonsmodellen er gjennomsnittsverdien i utvalget ditt. For m1 er dette gjennomsnittet for et utvalg på 8, og for m2 er det gjennomsnittet for et utvalg på 40.

For eksempel, i m1 er estimatet 1.84. Dette betyr at gjennomsnittlig forskjell mellom de to behandlingene i dette utvalget er 1.84.
Standard Error (SE): Standardfeilen er et mål på hvor presist du har estimert gjennomsnittet. Det er standardavviket delt på kvadratroten av utvalgsstørrelsen.

I m1 er SE = 1.251, som betyr at det er en viss usikkerhet rundt estimatet på 1.84.
t-value: t-verdien er et forhold mellom estimatet og standardfeilen: t = estimate / SE. Denne verdien sier noe om hvor mange ganger standardfeilen estimatet er fra 0.

For m1 er t-verdien 1.47, som betyr at estimatet er omtrent 1.47 standardfeiler unna null.
p-value: P-verdien viser sannsynligheten for å observere en t-verdi minst så ekstrem som den vi har, under antagelsen om at nullhypotesen er sann (at det ikke er noen forskjell mellom behandlingene). En høy p-verdi (som i m1 på 0.185) indikerer at vi ikke kan avvise nullhypotesen.


#for å finne p-verdiene for m1 og m2 gjer e følgande
```{r}
summary(m1)$coefficients[1, 4]
summary(m2)$coefficients[1, 4]

```
#2.
## Her ser vi at p-verdien til m1 er 0.185, og p-verdien til m2 er 0.002. Dermed er m2 under en p-verdi på 0.05, som indikerer at effekten er statistisk signifikant og lavere sansynlighet for at det skylder tilfeldige variasjoner. Større utvalgsstørrelser reduserer standardfeilen og øker sjansen for å oppdage en statistisk signifikant effekt. Dette skyldes at større utvalg gir et mer presist estimat av populasjonsgjennomsnittet.

#3
## På denne grafen, ser me eit skyggefullt areal på begge sidene, grunnet at dette er ein tosidig test (two-tailed). Det skyggefulle arealet i en t-fordeling representerer p-verdien, som viser sannsynligheita for å få ein t-verdi like ekstrem eller meir ekstrem enn den observerte, gitt at nullhypotesen er sann. Desto mindre arealet er, desto lavere er p-verdien, noko som indikerer sterkere bevis mot nullhypotesen og auker sansynlegheita for at forskjellen er signifikant.



#lage dataframes for å lagre estimatene
```{r}
results_8 <- data.frame(estimate = rep(NA, 1000), 
                      se = rep(NA, 1000), 
                      pval = rep(NA, 1000), 
                      n = 8)  

results_40 <- data.frame(estimate = rep(NA, 1000), 
                      se = rep(NA, 1000), 
                      pval = rep(NA, 1000), 
                      n = 40)

# A for loop used to sample 1000 studies, each iteration (i) will draw a new sample
# from the population. 

for(i in 1:1000) {
  
  # Draw a sample 
  samp1 <- data.frame(y = sample(population, 8, replace = FALSE))
  samp2 <- data.frame(y = sample(population, 40, replace = FALSE))

  # Model the data
  m1 <- lm(y ~ 1, data = samp1)
  m2 <- lm(y ~ 1, data = samp2)
  
  # Extract values from the models
  results_8[i, 1] <- coef(summary(m1))[1, 1]
  results_8[i, 2] <- coef(summary(m1))[1, 2]
  results_8[i, 3] <- coef(summary(m1))[1, 4]

  results_40[i, 1] <- coef(summary(m2))[1, 1]
  results_40[i, 2] <- coef(summary(m2))[1, 2]
  results_40[i, 3] <- coef(summary(m2))[1, 4]
  
  
}


# Save the results in a combined data frame

results <- bind_rows(results_8, results_40)
```



# for å finne verdiene for standardavviket og den gjennomsnittlege SE-verdien bruker eg følgande kommando
```{r}
# Standardavvik av estimater
sd(results_8$estimate)
sd(results_40$estimate)

# Gjennomsnittlig SE
mean(results_8$se)
mean(results_40$se)

```
#4.
##Sjølv om utvalgsstørrelsen er veldig forskjellig (40 mot 8), ser eg at SE og SD er ganske like fordi variabiliteten i dataene (SD) er lav i begge gruppene. SE justeres av utvalgsstørrelsen, men når SD er lav, blir denne justeringen mindre merkbar, spesielt i små grupper. Dette er grunnen til at SE og SD er nærme hverandre i begge grupper til tross for forskjellen i utvalgsstørrelse.


#Eksempel på kode for klipp og lim
```{r}
# A two facets histogram can be created with ggplot2
results %>%
  ggplot(aes(pval)) + 
  geom_histogram() +
  facet_wrap(~ n)


# Count the proportion of tests below a certain p-value for each 
results %>%
  filter(pval < 0.05) %>%
  group_by(n) %>%
  summarise(sig_results = n()/1000)



pwr.t.test(n = 40, sig.level = 0.05, d = 1.5/3, type = "one.sample")
```
#5
## I dette histogrammet ser me fordelingen av p-verdier fra dei to gruppene med ulik utvalgstørrelse. Her ser me at eit større utvalg vil føre til fleire signifikante p-verdier, noko som indikerer ein økt statistisk styrke med større utvalg. 



# for å beregne antall statistisk signifikante. Her velger eg at terskelen for signifikans er <0.05.
```{r}
results %>%
  filter(pval < 0.05) %>%
  group_by(n) %>%
  summarise(sig_results = n()/1000)

```
#6
### Her får eg verdien 0.234 for n = 8, og 0.863 for n = 40. Dette vil seie at omtrent 23,4% av desse studiene med n = 8, vil rapportere ein statistisk signifikant effekt på ( p < 0.05). Dette indikerer ein relativt lav statistisk styrke. I studien med n = 40 er det derimot omtrent 86.3% sjangse for å rapportere ein p-verdi på over 0.05. Dette er ein betydelig større sansynligheit for å oppdage ein statistisk signifikant signifikant effekt dersom det faktisk er ein reel effekt i populasjonen. 



# for å kalkulere styrken på de ulike one-sample t-testene bruker jeg følgende kode
```{r}
library(pwr)
pwr.t.test(n = 8, sig.level = 0.05, d = 1.5/3, type = "one.sample")
pwr.t.test(n = 40, sig.level = 0.05, d = 1.5/3, type = "one.sample")

```
#7
# Den statistiske styrken til n = 8 er 0.232. Dette indikerer at det er en høg risiko for å oppnå ein type 1 feil. Dette samsvarer med resultatene fra simuleringen som sa at 23.4% av studiene med n = 8 ble signifikante. På den andre sida ser me at n = 40 ender på 0.869. Dette er ein god styrke for å oppdage en effekt. Sjølv om nokon studier ønsker en styrke på over 0.9, er dette forstatt en god indikator for å rapportere signifikante resultater. Denne styrken samvarer også godt med simuleringen, som var på 86.3% for n = 40.


#Mange studier uten populasjonseffekten
```{r}
population <- rnorm(1000000, mean = 0, sd = 3)


# Create data frames to store the model estimates
results_8 <- data.frame(estimate = rep(NA, 1000), 
                      se = rep(NA, 1000), 
                      pval = rep(NA, 1000), 
                      n = 8)  

results_40 <- data.frame(estimate = rep(NA, 1000), 
                      se = rep(NA, 1000), 
                      pval = rep(NA, 1000), 
                      n = 40)

# A for loop used to sample 1000 studies, each iteration (i) will draw a new sample
# from the population. 

for(i in 1:1000) {
  
  # Draw a sample 
  samp1 <- data.frame(y = sample(population, 8, replace = FALSE))
  samp2 <- data.frame(y = sample(population, 40, replace = FALSE))

  # Model the data
  m1 <- lm(y ~ 1, data = samp1)
  m2 <- lm(y ~ 1, data = samp2)
  
  # Extract values from the models
  results_8[i, 1] <- coef(summary(m1))[1, 1]
  results_8[i, 2] <- coef(summary(m1))[1, 2]
  results_8[i, 3] <- coef(summary(m1))[1, 4]

  results_40[i, 1] <- coef(summary(m2))[1, 1]
  results_40[i, 2] <- coef(summary(m2))[1, 2]
  results_40[i, 3] <- coef(summary(m2))[1, 4]
  
  
}


# Save the results in a combined data frame

results_null <- bind_rows(results_8, results_40)
```

# Lag histogrammer for p-verdiene
```{r}
results_null %>%
  ggplot(aes(pval)) + 
  geom_histogram(bins = 30, fill = "blue", alpha = 0.7) +
  facet_wrap(~ n) + 
  labs(title = "Distribusjon av P-verdier",
       x = "P-verdi",
       y = "Antall studier") +
  theme_minimal()

```

# Beregn antall falske positive resultater
```{r}
false_positives <- results_null %>%
  filter(pval < 0.05) %>%
  group_by(n) %>%
  summarise(sig_results = n() / 1000)

# Skriv ut resultatene
print(false_positives)

```
#8
#I simuleringen undersøkte eg andelen falske positive resultater for utvalgsstørrelser på 8 og 40. For utvalget på 8 var andelen som gav signifikante p-verdier 3.8%, mens den for utvalget på 40 var 4.4%.

Desse resultatene viser at sjølv uten ein reell effekt kan et betydeleg antall studier gi falske positive resultater. Vanlegvis forventer me at større utvalg reduserer sleke tilfeller, men her kan tilfeldige variasjoner i større prøver føre til fleire feilaktege signifikante funn.

Funnene understreker viktigheten av å være kritisk til p-verdier og forstå potensielle utfordringer med falske positive i statistiske analyser.

